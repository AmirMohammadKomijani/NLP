{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akbYQBFjLjoc"
      },
      "source": [
        "1.Submit a Google Colab notebook containing your completed code and experimentation results.\n",
        "\n",
        "2.Include comments and explanations in your code to help understand the implemented logic.\n",
        "\n",
        "**Additional Notes:**\n",
        "*   Ensure that the notebook runs successfully in Google Colab.\n",
        "*   Document any issues encountered during experimentation and how you addressed them.\n",
        "\n",
        "**Grading:**\n",
        "*   Each task will be graded out of the specified points.\n",
        "*   Points will be awarded for correctness, clarity of code, thorough experimentation, and insightful analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoUu86p1Or1n"
      },
      "source": [
        "# Prediction-Based Word Vectors\n",
        "\n",
        "more recently prediction-based word vectors have demonstrated better performance, such as word2vec and GloVe (which also utilizes the benefit of counts). Here, we shall explore the embeddings produced by GloVe.\n",
        "\n",
        "Then run the following cells to load the GloVe vectors into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvpYg_7pODYJ",
        "outputId": "69df376f-3865-467b-e6ac-697afda31a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 252.1/252.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "import pprint\n",
        "wv_from_bin = api.load(\"glove-wiki-gigaword-200\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFfCOLUsSSuS"
      },
      "source": [
        "### Words with Multiple Meanings\n",
        "Polysemes and homonyms are words that have more than one meaning (see this [wiki page](https://en.wikipedia.org/wiki/Polysemy) to learn more about the difference between polysemes and homonyms ). Find a word with *at least two different meanings* such that the top-10 most similar words (according to cosine similarity) contain related words from *both* meanings. For example, \"leaves\" has both \"go_away\" and \"a_structure_of_a_plant\" meaning in the top 10, and \"scoop\" has both \"handed_waffle_cone\" and \"lowdown\". You will probably need to try several polysemous or homonymic words before you find one.\n",
        "\n",
        "Please state the word you discover and the multiple meanings that occur in the top 10. Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain **one** of the meanings of the words)?\n",
        "\n",
        "**Note**: You should use the `wv_from_bin.most_similar(word)` function to get the top 10 similar words. This function ranks all other words in the vocabulary with respect to their cosine similarity to the given word. For further assistance, please check the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar)__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAr09U-xSSuT",
        "outputId": "634a64c6-4a01-4d70-e529-55aaa4e1c9a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('leaving', 0.8048902153968811),\n",
              " ('right', 0.7165082097053528),\n",
              " ('back', 0.7087967991828918),\n",
              " ('went', 0.6952051520347595),\n",
              " ('out', 0.6867292523384094),\n",
              " ('leave', 0.6815778017044067),\n",
              " ('when', 0.677730917930603),\n",
              " ('returned', 0.6693609356880188),\n",
              " ('came', 0.6677366495132446),\n",
              " ('but', 0.6625413298606873)]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### CODE HERE\n",
        "word = 'left'\n",
        "similar_words = wv_from_bin.most_similar(word)\n",
        "similar_words\n",
        "# len(similar_words) = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdQ018tjSSuT"
      },
      "source": [
        "### SOLUTION\n",
        "Please state the word you discover and the multiple meanings that occur in the top 10. Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain **one** of the meanings of the words)?<br>\n",
        "\n",
        "**Answer :**<br>\n",
        "it can have many reasons why many of polysemous of homynomic didn't work. one of them can be co-occurence with one of its meaning is much more than the other one like the word \"bank\".<br>\n",
        "if we test this word we can see words about finances.<br>\n",
        "this can cause dominant meaning for one word and most_similar reflect one meaning of a word.<br>\n",
        "**Example :**<br> \n",
        "for \"left\" , we have two meanings : 1) direction 2) past tense of Leave <br>\n",
        "in the output we can observe similar words for both meanings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfeW-eK9SSuU"
      },
      "source": [
        "### Synonyms & Antonyms\n",
        "\n",
        "When considering Cosine Similarity, it's often more convenient to think of Cosine Distance, which is simply 1 - Cosine Similarity.\n",
        "\n",
        "Find three words $(w_1,w_2,w_3)$ where $w_1$ and $w_2$ are synonyms and $w_1$ and $w_3$ are antonyms, but Cosine Distance $(w_1,w_3) <$ Cosine Distance $(w_1,w_2)$.\n",
        "\n",
        "As an example, $w_1$=\"happy\" is closer to $w_3$=\"sad\" than to $w_2$=\"cheerful\". Please find a different example that satisfies the above. Once you have found your example, please give a possible explanation for why this counter-intuitive result may have happened.\n",
        "\n",
        "You should use the the `wv_from_bin.distance(w1, w2)` function here in order to compute the cosine distance between two words. Please see the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance)__ for further assistance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwlpPjpHSSuV",
        "outputId": "d64d46b1-54dc-4b1b-e4c5-a2f513fc5091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synonyms advantage, benefit have cosine distance: 0.48551487922668457\n",
            "Antonyms advantage, disadvantage have cosine distance: 0.36569714546203613\n"
          ]
        }
      ],
      "source": [
        "w1 = 'advantage'\n",
        "w2 = 'benefit'\n",
        "w3 = 'disadvantage'\n",
        "w1_w2_dist = wv_from_bin.distance(w1, w2)\n",
        "w1_w3_dist = wv_from_bin.distance(w1, w3)\n",
        "\n",
        "print(\"Synonyms {}, {} have cosine distance: {}\".format(w1, w2, w1_w2_dist))\n",
        "print(\"Antonyms {}, {} have cosine distance: {}\".format(w1, w3, w1_w3_dist))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIHjTFMSSuV"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "**Question :** Please find a different example that satisfies the above. Once you have found your example, please give a possible explanation for why this counter-intuitive result may have happened.\n",
        "\n",
        "**Answer :**<br>\n",
        "first, my example : advantage and disadvantage are antonyms and have cosine distance = 0.36 which is less than cosine distance between advantage and benefit which are almost synonyms.<br>\n",
        "\n",
        "for explaining the counter-intuitive result which some antonyms have less cosine distance than some synonyms,we may occur many reasons:<br>\n",
        "**1)** word co-occurence : we know that glove algorithm works with co-occurence matrix => maybe two antonyms can be observed with each other more than synonyms and it can lead us to more similar vectors and less cosine distance.<br>\n",
        "\n",
        "**2)** there is also another reason that sometimes appear in glove ,but not related with my examples, is some gender biases.<br>\n",
        "\n",
        "**Result** = for this algorithm,GLoVE, because of more co-occurences of antonyms it can cause this happening."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxIDq26zSSuW"
      },
      "source": [
        "### Analogies with Word Vectors\n",
        "Word vectors have been shown to *sometimes* exhibit the ability to solve analogies.\n",
        "\n",
        "As an example, for the analogy \"man : grandfather :: woman : x\" (read: man is to grandfather as woman is to x), what is x?\n",
        "\n",
        "In the cell below, we show you how to use word vectors to find x using the `most_similar` function from the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.most_similar)__. The function finds words that are most similar to the words in the `positive` list and most dissimilar from the words in the `negative` list. The answer to the analogy will have the highest cosine similarity (largest returned numerical value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0pC7H4VSSuY",
        "outputId": "a1552371-80d0-41db-c872-cafbd8cb60b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('grandmother', 0.7608445286750793),\n",
            " ('granddaughter', 0.7200808525085449),\n",
            " ('daughter', 0.7168302536010742),\n",
            " ('mother', 0.7151536345481873),\n",
            " ('niece', 0.7005682587623596),\n",
            " ('father', 0.6659887433052063),\n",
            " ('aunt', 0.6623408794403076),\n",
            " ('grandson', 0.6618767976760864),\n",
            " ('grandparents', 0.644661009311676),\n",
            " ('wife', 0.6445354223251343)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to answer the analogy -- man : grandfather :: woman : x\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'grandfather'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVv8I9WwSSuZ"
      },
      "source": [
        "Let $m$, $g$, $w$, and $x$ denote the word vectors for `man`, `grandfather`, `woman`, and the answer, respectively. Using **only** vectors $m$, $g$, $w$, and the vector arithmetic operators $+$ and $-$ in your answer, to what expression are we maximizing $x$'s cosine similarity?\n",
        "\n",
        "Hint: Recall that word vectors are simply multi-dimensional vectors that represent a word. It might help to draw out a 2D example using arbitrary locations of each vector. Where would `man` and `woman` lie in the coordinate plane relative to `grandfather` and the answer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUKBqtHSSuZ"
      },
      "source": [
        "### SOLUTION\n",
        "**Question :** Using only vectors  m ,  g ,  w , and the vector arithmetic operators  +  and  −  in your answer, to what expression are we maximizing  x 's cosine similarity?<br>\n",
        "\n",
        "**Answer :**<br>\n",
        "the arithmetic relationship that we set : **x = g + (w - m)**\n",
        "this causes the result grandmother which has the most rank in our code output.<br>\n",
        "\n",
        "cosine similarity : Cosine similarity measures how similar two vectors are in direction, regardless of their magnitude. In our case, we want the answer vector (x) to have a direction as close as possible to a specific direction defined by other word vectors.<br>\n",
        "\n",
        "for plotting 2d part we can assume **gender** as x-axis and another arbitary like age or ...whatever as y-axis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRgMca9SSua"
      },
      "source": [
        "### Finding Analogies\n",
        "a. For the previous example, it's clear that \"grandmother\" completes the analogy. But give an intuitive explanation as to why the `most_similar` function gives us words like \"granddaughter\", \"daughter\", or \"mother?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgYQXazQSSua"
      },
      "source": [
        "### SOLUTION\n",
        "**Question :**  For the previous example, it's clear that \"grandmother\" completes the analogy. But give an intuitive explanation as to why the most_similar function gives us words like \"granddaughter\", \"daughter\", or \"mother? <br>\n",
        "**Answer :**<br>\n",
        "The most_similar function considers overall vector similarity, not just directional shifts. Words like \"daughter\" or \"mother\" might be closer to \"woman\" in the vector space due to various semantic factors, even though they don't perfectly capture the gender and generational shift like \"grandmother\".\n",
        "Word vectors can encode complex relationships. \"Daughter\" might be close to \"woman\" because they both relate to family, even though it doesn't fulfill the specific analogy requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9aAUXEISSub"
      },
      "source": [
        "b. Find an example of analogy that holds according to these vectors (i.e. the intended word is ranked top). In your solution please state the full analogy in the form x:y :: a:b. If you believe the analogy is complicated, explain why the analogy holds in one or two sentences.\n",
        "\n",
        "**Note**: You may have to try many analogies to find one that works!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dhzQJMYYVSjf"
      },
      "outputs": [],
      "source": [
        "x, y, a, b = \"man\", \"woman\", \"king\", \"queen\"\n",
        "assert wv_from_bin.most_similar(positive=[a, y], negative=[x])[0][0] == b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3QlPqAwSSub"
      },
      "source": [
        "### SOLUTION\n",
        "**Question : ** In your solution please state the full analogy in the form x:y :: a:b. If you believe the analogy is complicated, explain why the analogy holds in one or two sentences.<br>\n",
        "Analogy : man:woman :: king:queen**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwgcEywwSSuc"
      },
      "source": [
        "### Incorrect Analogy\n",
        "a. Below, we expect to see the intended analogy \"hand : glove :: foot : **sock**\", but we see an unexpected result instead. Give a potential reason as to why this particular analogy turned out the way it did?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-ykWoJoSSuc",
        "outputId": "160d3197-9eb3-42e6-b760-35d809340a4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('45,000-square', 0.4922032654285431),\n",
            " ('15,000-square', 0.4649604558944702),\n",
            " ('10,000-square', 0.4544755816459656),\n",
            " ('6,000-square', 0.44975775480270386),\n",
            " ('3,500-square', 0.444133460521698),\n",
            " ('700-square', 0.44257497787475586),\n",
            " ('50,000-square', 0.4356396794319153),\n",
            " ('3,000-square', 0.43486514687538147),\n",
            " ('30,000-square', 0.4330596923828125),\n",
            " ('footed', 0.43236875534057617)]\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(wv_from_bin.most_similar(positive=['foot', 'glove'], negative=['hand']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn4ruS8MSSud"
      },
      "source": [
        "### SOLUTION\n",
        "**Question :**<br> Below, we expect to see the intended analogy \"hand : glove :: foot : sock\", but we see an unexpected result instead. Give a potential reason as to why this particular analogy turned out the way it did?<br>\n",
        "**Answer :**<br>\n",
        "**1)** Polysemy and Word Embeddings: Words like \"foot\" and \"glove\" have multiple meanings (polysemy). Word embeddings often capture the most frequent or dominant meaning for a word. In this case, the word \"foot\" might be primarily associated with units of area (square footage) in the word vector space you're using. This overshadows the intended meaning related to the body part.<br>\n",
        "**2)** Dataset Bias: The training data used to create the word vectors might influence the resulting embeddings. If the data primarily uses \"foot\" in the context of area measurements, the resulting vector will likely reflect that dominant meaning.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gHyZt0SSud"
      },
      "source": [
        ":b. Find another example of analogy that does *not* hold according to these vectors. In your solution, state the intended analogy in the form x:y :: a:b, and state the **incorrect** value of b according to the word vectors (in the previous example, this would be **'45,000-square'**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_rlci42XQTw",
        "outputId": "e8b2511e-0316-43de-9605-e778b29da991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('snowfall', 0.5256644487380981),\n",
            " ('heavy', 0.463622123003006),\n",
            " ('slippery', 0.45968130230903625),\n",
            " ('snowfalls', 0.4593408405780792),\n",
            " ('wet', 0.4542512893676758),\n",
            " ('snows', 0.4535849094390869),\n",
            " ('stuck', 0.45239710807800293),\n",
            " ('cold', 0.44439494609832764),\n",
            " ('ice', 0.44195353984832764),\n",
            " ('mud', 0.44139257073402405)]\n"
          ]
        }
      ],
      "source": [
        "x, y, a, b = \"sun\", \"hot\", \"snow\",\"cold\"\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[a, y], negative=[x]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4x0EHjeSSue"
      },
      "source": [
        "### SOLUTION\n",
        "**Question :** Find another example of analogy that does not hold according to these vectors. In your solution, state the intended analogy in the form x:y :: a:b, and state the incorrect value of b according to the word vectors<br>\n",
        "\n",
        "**Answer :**<br>\n",
        "analog -> sun:hot :: snow:cold <br>\n",
        "the output result is : snowfall,heavy,slippery ,...<br>\n",
        "which are not correct because sun is the source of warmth and hot is a weather situation which is caused by son. and snow is kinda source of cold weather.<br>\n",
        "but in the output cold is ranked among the last ones which is incorrect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvlycXN-SSuf"
      },
      "source": [
        "### Guided Analysis of Bias in Word Vectors\n",
        "\n",
        "It's important to be cognizant of the biases (gender, race, sexual orientation etc.) implicit in our word embeddings. Bias can be dangerous because it can reinforce stereotypes through applications that employ these models.\n",
        "\n",
        "Run the cell below, to examine (a) which terms are most similar to \"woman\" and \"profession\" and most dissimilar to \"man\", and (b) which terms are most similar to \"man\" and \"profession\" and most dissimilar to \"woman\". Point out the difference between the list of female-associated words and the list of male-associated words, and explain how it is reflecting gender bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XggWA4MhSSuf",
        "outputId": "ed74823b-27c2-4b50-ff64-40c85c6405a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('reputation', 0.5250176787376404),\n",
            " ('professions', 0.5178037881851196),\n",
            " ('skill', 0.49046966433525085),\n",
            " ('skills', 0.49005505442619324),\n",
            " ('ethic', 0.4897659420967102),\n",
            " ('business', 0.4875852167606354),\n",
            " ('respected', 0.485920250415802),\n",
            " ('practice', 0.482104629278183),\n",
            " ('regarded', 0.4778572618961334),\n",
            " ('life', 0.4760662019252777)]\n",
            "\n",
            "[('professions', 0.5957457423210144),\n",
            " ('practitioner', 0.49884122610092163),\n",
            " ('teaching', 0.48292139172554016),\n",
            " ('nursing', 0.48211804032325745),\n",
            " ('vocation', 0.4788965880870819),\n",
            " ('teacher', 0.47160351276397705),\n",
            " ('practicing', 0.46937814354896545),\n",
            " ('educator', 0.46524327993392944),\n",
            " ('physicians', 0.4628995358943939),\n",
            " ('professionals', 0.4601394236087799)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell\n",
        "# Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be most dissimilar from.\n",
        "\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['man', 'profession'], negative=['woman']))\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'profession'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4g6KbsYSSuh"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "**Question :** explain how it is reflecting gender bias.<br>\n",
        "**Answer :**<br>\n",
        "This bias likely arises from the training data used to create the word embeddings. If the data primarily contains text where professions are associated with specific genders, the word vectors will reflect those biases.  For example, if there are many mentions of \"doctor\" and \"he\" together, the word vector for \"doctor\" might lean towards male doctors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxJmnS6lSSui"
      },
      "source": [
        "### Independent Analysis of Bias in Word Vectors\n",
        "\n",
        "Use the `most_similar` function to find another pair of analogies that demonstrates some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZoDheIfSSui",
        "outputId": "8cab38fc-0530-493a-d806-9990174a567a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('foods', 0.5010936260223389),\n",
            " ('care', 0.4917422831058502),\n",
            " ('nutrition', 0.4827004373073578),\n",
            " ('for', 0.47490009665489197),\n",
            " ('u.s.', 0.47357606887817383),\n",
            " ('americans', 0.4723329544067383),\n",
            " ('supplies', 0.4687662422657013),\n",
            " ('products', 0.4552023708820343),\n",
            " ('canadian', 0.4544133245944977),\n",
            " ('medicine', 0.45267990231513977)]\n",
            "\n",
            "[('vegetables', 0.5511559844017029),\n",
            " ('asia', 0.5381689071655273),\n",
            " ('foods', 0.4933627247810364),\n",
            " ('fresh', 0.47798046469688416),\n",
            " ('supplies', 0.4774106442928314),\n",
            " ('prices', 0.47332215309143066),\n",
            " ('thailand', 0.46969538927078247),\n",
            " ('seafood', 0.463384747505188),\n",
            " ('markets', 0.4559096097946167),\n",
            " ('eaten', 0.45554429292678833)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "A = \"american\"\n",
        "B = \"asian\"\n",
        "word = \"food\"\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[A, word], negative=[B]))\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[B, word], negative=[A]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGOlmtJoSSuj"
      },
      "source": [
        "### SOLUTION\n",
        "**Question :** Use the most_similar function to find another pair of analogies that demonstrates some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover.<br>\n",
        "**Answer :**<br>\n",
        "i found words american and asian and their bias occurs with word \"food\". for sure,they have some common words but they have some different words that similar with american word and dissimilar with asian and opposite.<br>\n",
        "for example the word seafood or vegetables are common food in asian meals but not so common in american food.\n",
        "actualy this example reflects the bias in race or location.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK2XVWzmSSuk"
      },
      "source": [
        "### Thinking About Bias\n",
        "\n",
        "a. Give one explanation of how bias gets into the word vectors. Briefly describe a real-world example that demonstrates this source of bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19pM85fCSSuk"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "**َAnswer :**<br>\n",
        "One primary way bias gets into word vectors is through data bias. This happens when the training data used to create the word embeddings itself reflects societal biases. Word embeddings are trained on massive amounts of text data, and the statistical patterns within this data are captured in the resulting vectors.\n",
        "**Real World example :**<br>\n",
        "Imagine a word embedding model trained on a dataset consisting primarily of news articles. These articles might frequently mention male doctors and female nurses. As a result, the word vector for \"doctor\" might end up closer to words like \"male\" and \"surgeon\" in the vector space, while the word vector for \"nurse\" might be closer to words like \"female\" and \"caring.\" This reflects the existing societal bias in these professions within the training data, perpetuating the stereotype in the word embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILYqJZ7ASSul"
      },
      "source": [
        "b. What is one method you can use to mitigate bias exhibited by word vectors?  Briefly describe a real-world example that demonstrates this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJaAB7mSSul"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "**َAnswer :**<br>\n",
        "**1) Debiasing Techniques :**  Analyze the vector space to identify directions that encode specific biases (e.g., gender, race). This can be done by studying known biased word pairs.Several debiasing techniques exist, such as projecting out the bias direction or rotating the word vectors in a way that reduces bias.<br>\n",
        "\n",
        "**2) Balanced Training Data :** Ensure the training data used to create the word embeddings is balanced and representative of the population you want to capture. This means including text from diverse sources and avoiding datasets that reinforce stereotypes.<br>\n",
        "Techniques like data augmentation can be used to artificially create more balanced datasets from existing data. This can help reduce bias if the original data is skewed."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
