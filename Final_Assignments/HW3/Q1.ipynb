{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK-0syxkWi21"
      },
      "source": [
        "# Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX0LV_hrWPsG"
      },
      "source": [
        "\n",
        "*   In this question we want to use POS-tagged training set to compute for each word the tag that maximizes $p(t|w)$.\n",
        "*   We will implement a simple tokenizer to deal with sentence boundaries.\n",
        "*   We start by assuming that all unknown words are NN and compute error rate on known and unknown words.\n",
        "*   Then write at least five rules to do a better job of tagging unknown words, and show the difference in error rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lueYCsOI0WgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1546b22a-c1a0-4191-fd70-eb82d7fb3939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import math\n",
        "\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9ppIGG8ZWv1c"
      },
      "outputs": [],
      "source": [
        "def generate_dict(_samples):\n",
        "    \"\"\"\n",
        "    Generate a dictionary that captures the count of each (word, tag) combination from a list of samples.\n",
        "\n",
        "    Args:\n",
        "    _samples (list): List of tuples containing (word, tag) pairs.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are words and values are lists of dictionaries with 'tag' and 'count' keys.\n",
        "          Each dictionary in the list represents a unique tag associated with the word and its count.\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "    Example:\n",
        "      _samples = [('apple', 'fruit'), ('banana', 'fruit'), ('apple', 'fruit'), ('apple', 'color'), ('banana', 'color')]\n",
        "      After calling generate_dict(_samples), the expected output would be:\n",
        "      {\n",
        "          'apple': [\n",
        "              {'tag': 'fruit', 'count': 2},\n",
        "              {'tag': 'color', 'count': 1}\n",
        "          ],\n",
        "          'banana': [\n",
        "              {'tag': 'fruit', 'count': 1},\n",
        "              {'tag': 'color', 'count': 1}\n",
        "          ]\n",
        "      }\n",
        "      This represents that 'apple' appeared twice with the tag 'fruit' and once with the tag 'color',\n",
        "      while 'banana' appeared once with both 'fruit' and 'color' tags.\n",
        "\n",
        "    '''\n",
        "\n",
        "    dictionary = {}\n",
        "\n",
        "\n",
        "    ## Your code here\n",
        "    # create the dictionary described in the comments\n",
        "    # Populate the dictionary with word-tag counts\n",
        "    for word, tag in _samples:\n",
        "        if word in dictionary:\n",
        "            # Check if the tag already exists for the word\n",
        "            tag_exists = False\n",
        "            for item in dictionary[word]:\n",
        "                if item['tag'] == tag:\n",
        "                    item['count'] += 1\n",
        "                    tag_exists = True\n",
        "                    break\n",
        "            if not tag_exists:\n",
        "                dictionary[word].append({'tag': tag, 'count': 1})\n",
        "        else:\n",
        "            dictionary[word] = [{'tag': tag, 'count': 1}]\n",
        "\n",
        "    ## End Code\n",
        "    def get_tag_counts(subitem):\n",
        "        return subitem['count']\n",
        "\n",
        "    for item in dictionary:\n",
        "        sorted(dictionary[item], key=get_tag_counts, reverse=True)\n",
        "\n",
        "    return dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "C-wu5AVoX_rN"
      },
      "outputs": [],
      "source": [
        "def predict_tag(_test_set, _tag_dict):\n",
        "    \"\"\"\n",
        "    Predicts the tags for a given test set of words based on a provided tag dictionary.\n",
        "\n",
        "    Args:\n",
        "    _test_set (list): A list of tuples containing (word, true_tag) pairs to be predicted.\n",
        "    _tag_dict (dict): A dictionary containing words as keys and lists of dictionaries with 'tag' and 'count' keys as values.\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy of the predictions, calculated as the ratio of correct predictions to the total number of predictions.\n",
        "\n",
        "    Comments:\n",
        "    - For unknown words, 'NN' (noun) tag is assigned.\n",
        "    - Tags are assigned based on the highest count for known words.\n",
        "      - If there are more than 1 tag for a given word, the tag with the highest count is chosen.\n",
        "      - If there is only 1 tag available, it is returned directly.\n",
        "    \"\"\"\n",
        "\n",
        "    accuracy = 0\n",
        "    for item in _test_set:\n",
        "        word = item[0]\n",
        "        true_tag = item[1]\n",
        "        if word in _tag_dict:\n",
        "            prediction = max(_tag_dict[word], key=lambda x: x['count'])['tag'] ### result = 788 more words got correctly classified.\n",
        "            # prediction = _tag_dict[word][0]['tag'] ### result = 1110 more words got correctly classified.\n",
        "        else:\n",
        "            prediction = 'NN'\n",
        "        if prediction == true_tag:\n",
        "          accuracy +=1\n",
        "\n",
        "    accuracy /= len(_test_set)\n",
        "    print(f\"Assuming that all unknown words are NN\")\n",
        "    print(f\">> accuracy: {accuracy}\")\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SgXAgTDrcbYl"
      },
      "outputs": [],
      "source": [
        "def predict_tag_with_improvements(_test_set, _tag_dict):\n",
        "    \"\"\"\n",
        "    Predicts the tags for a given test set of words based on a provided tag dictionary, with additional rules for unknown words.\n",
        "\n",
        "    Args:\n",
        "    _test_set (list): A list of tuples containing (word, true_tag) pairs to be predicted.\n",
        "    _tag_dict (dict): A dictionary containing words as keys and lists of dictionaries with 'tag' and 'count' keys as values.\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy of the predictions, calculated as the ratio of correct predictions to the total number of predictions.\n",
        "\n",
        "    Comments:\n",
        "    - For unknown words, 'NN' (noun) tag is initially assigned.\n",
        "    - Additional rules are applied to analyze unknown words and assign more specific tags based on patterns observed in the word:\n",
        "        - 'VBG' (verb, gerund) for words ending in 'ing'\n",
        "        - 'NP$' (noun, possessive) for words ending in \"'s\"\n",
        "        - 'NNS' (noun, plural) for words ending in 's'\n",
        "        - 'RB' (adverb) for words ending in 'ly'\n",
        "        - 'VBN' (verb, past participle) for words ending in 'ed'\n",
        "        - 'JJ' (adjective) for words matching certain patterns like 'ble', 'ish', 'ful', etc.\n",
        "        - 'CD' (cardinal numeral) for numeric strings\n",
        "        - 'NP' (noun, proper singular) for capitalized words\n",
        "    \"\"\"\n",
        "\n",
        "    ## Your code here\n",
        "    accuracy = 0\n",
        "    total_predictions = len(_test_set)\n",
        "\n",
        "    for word, true_tag in _test_set:\n",
        "        if word in _tag_dict:\n",
        "            prediction = _tag_dict[word][0]['tag']\n",
        "        else:\n",
        "            if word.endswith('ing'):\n",
        "                prediction = 'VBG'\n",
        "            elif word.endswith(\"'s\"):\n",
        "                prediction = 'NP$'\n",
        "            elif word.endswith('s'):\n",
        "                prediction = 'NNS'\n",
        "            elif word.endswith('ly'):\n",
        "                prediction = 'RB'\n",
        "            elif word.endswith('ed'):\n",
        "                prediction = 'VBN'\n",
        "            elif any(pattern in word for pattern in ['ble', 'ish', 'ful']):\n",
        "                prediction = 'JJ'\n",
        "            elif word.isdigit():\n",
        "                prediction = 'CD'\n",
        "            elif word[0].isupper():\n",
        "                prediction = 'NP'\n",
        "            else:\n",
        "                # Default tag for unknown words\n",
        "                prediction = 'NN'\n",
        "\n",
        "        if prediction == true_tag:\n",
        "            accuracy += 1\n",
        "\n",
        "    ## End Code\n",
        "    accuracy /= len(_test_set)\n",
        "    print(f\"With additional rules for unknown words\")\n",
        "    print(f\">> accuracy: {accuracy}\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0P6OX_pEh_tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78452688-dd8f-499d-a5a0-d393e8e791a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set:     75415\n",
            "length of testing set:      25139\n",
            "Assuming that all unknown words are NN\n",
            ">> accuracy: 0.8312184255539202\n",
            "With additional rules for unknown words\n",
            ">> accuracy: 0.8626039221926091\n",
            "788 more words got correctly classified.\n"
          ]
        }
      ],
      "source": [
        "CORPUS = brown.tagged_words(categories='news')\n",
        "CORPUS_SIZE = len(brown.tagged_words(categories='news'))\n",
        "\n",
        "CUT_OFF = math.floor(CORPUS_SIZE * 0.75)\n",
        "\n",
        "# section off training and testing lists from corpus\n",
        "training_list = CORPUS[:CUT_OFF]\n",
        "testing_list = CORPUS[CUT_OFF:]\n",
        "\n",
        "# duplicates are ignored in sets\n",
        "training_set = set(training_list)\n",
        "testing_set = set(testing_list)\n",
        "intersection = training_set.intersection(testing_set)\n",
        "\n",
        "print(f\"length of training set:     {len(training_list)}\")\n",
        "print(f\"length of testing set:      {len(testing_list)}\")\n",
        "\n",
        "# uncomment to see how much the training set and testing set overlap\n",
        "# print(f\"intersection:               {len(intersection)}\")\n",
        "\n",
        "# uncomment to survey tagged corpus\n",
        "# print(training_set)\n",
        "\n",
        "tag_dict = generate_dict(training_list)\n",
        "accurary_base = predict_tag(testing_list, tag_dict)\n",
        "accurary_impr = predict_tag_with_improvements(testing_list, tag_dict)\n",
        "delta = math.floor((accurary_impr - accurary_base) * len(testing_list))\n",
        "print(f\"{delta} more words got correctly classified.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}